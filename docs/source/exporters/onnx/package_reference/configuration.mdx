<!--Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# Configuration classes for ONNX exports

Exporting a model to ONNX involves specifying:
1. The input names.
2. The output names.
3. The dynamic axes. These refer to the input dimensions can be changed dynamically at runtime (e.g. a batch size or sequence length).
All other axes will be treated as static, and hence fixed at runtime.
4. Dummy inputs to trace the model. This is needed in PyTorch to record the computational graph and convert it to ONNX.

Since this data depends on the choice of model and task, we represent it in terms of _configuration classes_. Each configuration class is associated with
a specific model architecture, and follows the naming convention `ArchitectureNameOnnxConfig`. For instance, the configuration which specifies the ONNX
export of BERT models is `BertOnnxConfig`.

Since many architectures share similar properties for their ONNX configuration, ðŸ¤— Optimum adopts a 3-level class hierarchy:
1. Abstract and generic base classes. These handle all the fundamental features, while being agnostic to the modality (text, image, audio, etc).
2. Middle-end classes. These are aware of the modality, but multiple can exist for the same modality depending on the inputs they support.
They specify which input generators should be used for the dummy inputs, but remain model-agnostic.
3. Model-specific classes like the `BertOnnxConfig` mentioned above. These are the ones actually used to export models.


## Base classes

[[autodoc]] exporters.onnx.OnnxConfig
    - inputs
    - outputs
    - generate_dummy_inputs

[[autodoc]] exporters.onnx.OnnxConfigWithPast
    - with_past

[[autodoc]] exporters.onnx.OnnxSeq2SeqConfigWithPast

## Middle-end classes

### Text

[[autodoc]] exporters.onnx.config.TextEncoderOnnxConfig

[[autodoc]] exporters.onnx.config.TextDecoderOnnxConfig

[[autodoc]] exporters.onnx.config.TextSeq2SeqOnnxConfig


### Vision

[[autodoc]] exporters.onnx.config.VisionOnnxConfig


### Multi-modal

[[autodoc]] exporters.onnx.config.TextAndVisionOnnxConfig

## Supported architectures

- Audio Spectrogram Transformer
- Albert
- Bart
- Beit
- Bert
- BigBird
- BigBirdPegasus
- BigBirdSmall
- BlenderBot
- Bloom
- CLIP
- Camembert
- CodeGen
- ConvBert
- ConvNext
- Data2VecAudio
- Data2VecText
- Data2VecVision
- Deberta
- Deberta-v2
- Deit
- Detr
- DistilBert
- Electra
- Flaubert
- GPT-2
- GPT-J
- GPT-Neo
- GroupVit
- Hubert
- IBert
- LayoutLM
- LayoutLM-v3
- Levit
- LongT5
- M2-M100
- MBart
- MT5
- Marian
- MobileBert
- MobileVit
- OwlVit
- Perceiver
- ResNet
- Roberta
- Roformer
- Segformer
- SEW
- Speech2Text
- SqueezeBert
- Stable Diffusion
- T5
- UniSpeech
- UniSpeech SAT
- Vit
- Wav2Vec2
- Wav2Vec2 Conformer
- WavLM
- Whisper
- XLM
- XLM-Roberta
- Yolos
