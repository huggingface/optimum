- sections:
  - local: index
    title: ü§ó Optimum
  - local: installation
    title: Installation
  - local: quicktour
    title: Quick tour
  - local: notebooks
    title: Notebooks
  - sections:
    - local: concept_guides/quantization
      title: Quantization
    title: Conceptual guides
  title: Overview
- sections:
  - local: onnxruntime/overview
    title: Overview
  - local: onnxruntime/quickstart
    title: Quick tour
  - sections:
    - local: onnxruntime/usage_guides/pipelines
      title: Inference pipelines
    - local: onnxruntime/usage_guides/models
      title: Models for inference
    - local: onnxruntime/usage_guides/optimization
      title: How to apply graph optimization
    - local: onnxruntime/usage_guides/quantization
      title: How to apply dynamic and static quantization
    - local: onnxruntime/usage_guides/trainer
      title: How to accelerate training
    - local: onnxruntime/usage_guides/gpu
      title: Accelerated inference on NVIDIA GPUs
    title: How-to guides
    isExpanded: false
  - sections:
    - local: onnxruntime/concept_guides/onnx
      title: ONNX ü§ù ONNX Runtime
    title: Conceptual guides
    isExpanded: false
  - sections:
    - local: onnxruntime/package_reference/modeling_ort
      title: ONNX Runtime Models
    - local: onnxruntime/package_reference/configuration
      title: Configuration
    - local: onnxruntime/package_reference/optimization
      title: Optimization
    - local: onnxruntime/package_reference/quantization
      title: Quantization
    - local: onnxruntime/package_reference/trainer
      title: Trainer
    title: Reference
    isExpanded: false
  title: ONNX Runtime
- sections:
  - local: exporters/overview
    title: Overview
  - local: exporters/task_manager
    title: The TasksManager
  - sections:
    - local: exporters/onnx/overview
      title: Overview
    - sections:
      - local: exporters/onnx/usage_guides/export_a_model
        title: Export a model to ONNX
      - local: exporters/onnx/usage_guides/contribute
        title: Add support for exporting an architecture to ONNX
      title: How-to guides
    - sections:
      - local: exporters/onnx/package_reference/configuration
        title: ONNX configurations
      - local: exporters/onnx/package_reference/export
        title: Export functions
      title: Reference
      isExpanded: false
    title: "ONNX"
  - sections:
    - local: exporters/tflite/overview
      title: Overview
    - sections:
      - local: exporters/tflite/usage_guides/export_a_model
        title: Export a model to TFLite
      - local: exporters/tflite/usage_guides/contribute
        title: Add support for exporting an architecture to TFLite
      title: How-to guides
    - sections:
      - local: exporters/tflite/package_reference/configuration
        title: TFLite configurations
      - local: exporters/tflite/package_reference/export
        title: Export functions
      title: Reference
      isExpanded: false
    title: "TFLite"
  title: Exporters
- sections:
  - local: torch_fx/overview
    title: Overview
  - sections:
    - local: torch_fx/usage_guides/optimization
      title: Optimization
    title: How-to guides
    isExpanded: false
  - sections:
    - local: torch_fx/concept_guides/symbolic_tracer
      title: Symbolic tracer
    title: Conceptual guides
    isExpanded: false
  - sections:
    - local: torch_fx/package_reference/optimization
      title: Optimization
    title: Reference
    isExpanded: false
  title: Torch FX
- sections:
  - local: bettertransformer/overview
    title: Overview
  - sections:
    - local: bettertransformer/tutorials/convert
      title: Convert Transformers models to use BetterTransformer
    - local: bettertransformer/tutorials/contribute
      title: How to add support for new architectures?
    title: Tutorials
    isExpanded: false
  title: BetterTransformer
- sections:
  - local: utils/dummy_input_generators
    title: Dummy input generators
  - local: utils/normalized_config
    title: Normalized configurations
  title: Utilities
  isExpanded: false
