# Optimum Graphcore
graphcore_index: graphcore/index
graphcore_quickstart: graphcore/quickstart
graphcore_ipu_config: graphcore/ipu_config
graphcore_trainer: graphcore/trainer
graphcore_add_support_for_new_model: graphcore/add_support_for_new_model

# Optimum Habana
habana_index: habana/index
habana_quickstart: habana/quickstart
habana_single_hpu: habana/tutorials/single_hpu
habana_distributed: habana/tutorials/distributed
habana_deepspeed: habana/usage_guides/deepspeed
habana_accelerate_training: habana/usage_guides/accelerate_training
habana_trainer: habana/package_reference/trainer
habana_gaudi_config: habana/package_reference/gaudi_config
habana/usage_guides/stable_diffusion: habana/tutorials/stable_diffusion
habana/tutorials/pretraining: habana/usage_guides/pretraining

# Optimum Intel
intel_index: intel/index
intel_quickstart: intel/index
intel_configuration: intel/neural_compressor/reference
intel_optimization: intel/neural_compressor/optimization
intel_quantization: intel/neural_compressor/optimization
intel_pruning: intel/neural_compressor/optimization
intel_trainer: intel/neural_compressor/reference
intel/inference: intel/openvino/inference
intel/optimization_ov: intel/openvino/optimization
intel/reference_ov: intel/openvino/reference
intel/optimization_inc: intel/neural_compressor/optimization
intel/distributed_training: intel/neural_compressor/distributed_training
intel/reference_inc: intel/neural_compressor/reference

# Optimum Neuron
docs/optimum-neuron/index: /docs/optimum-neuron/index

# Optimum TPU
docs/optimum-tpu/index: /docs/optimum-tpu/index
tpu/index: /docs/optimum-tpu/index

# Optimum ExecuTorch
docs/optimum-executorch/index: /docs/optimum-executorch/index

# Optimum ONNX
docs/optimum-onnx/index: /docs/optimum-onnx/index
onnxruntime/overview: /docs/optimum-onnx/onnxruntime/overview
onnxruntime/quickstart: /docs/optimum-onnx/onnxruntime/quickstart
onnxruntime/usage_guides/pipelines: /docs/optimum-onnx/onnxruntime/usage_guides/pipelines
onnxruntime/usage_guides/models: /docs/optimum-onnx/onnxruntime/usage_guides/models
onnxruntime/usage_guides/optimization: /docs/optimum-onnx/onnxruntime/usage_guides/optimization
onnxruntime/usage_guides/quantization: /docs/optimum-onnx/onnxruntime/usage_guides/quantization
onnxruntime/usage_guides/trainer: /docs/optimum-onnx/onnxruntime/usage_guides/trainer
onnxruntime/usage_guides/gpu: /docs/optimum-onnx/onnxruntime/usage_guides/gpu
onnxruntime/usage_guides/amdgpu: /docs/optimum-onnx/onnxruntime/usage_guides/amdgpu
onnxruntime/concept_guides/onnx: /docs/optimum-onnx/onnxruntime/concept_guides/onnx
onnxruntime/package_reference/modeling_ort: /docs/optimum-onnx/onnxruntime/package_reference/modeling_ort
onnxruntime/package_reference/configuration: /docs/optimum-onnx/onnxruntime/package_reference/configuration
onnxruntime/package_reference/optimization: /docs/optimum-onnx/onnxruntime/package_reference/optimization
onnxruntime/package_reference/quantization: /docs/optimum-onnx/onnxruntime/package_reference/quantization
onnxruntime/package_reference/trainer: /docs/optimum-onnx/onnxruntime/package_reference/trainer
exporters/onnx/overview: /docs/optimum-onnx/onnx/overview
exporters/onnx/usage_guides/export_a_model: /docs/optimum-onnx/onnx/usage_guides/export_a_model
exporters/onnx/usage_guides/contribute: /docs/optimum-onnx/onnx/usage_guides/contribute
exporters/onnx/package_reference/configuration: /docs/optimum-onnx/onnx/package_reference/configuration
exporters/onnx/package_reference/export: /docs/optimum-onnx/onnx/package_reference/export