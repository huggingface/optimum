# coding=utf-8
# Copyright 2022 The HuggingFace Team. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


VALIDATE_EXPORT_ON_SHAPES_SLOW = {
    "batch_size": [1, 3, 5],
    "sequence_length": [8, 33, 96, 154],
    "num_choices": [2, 4],
    "audio_sequence_length": [1000, 2000],
    "point_batch_size": [1, 5],
    "nb_points_per_image": [1, 3],
}

VALIDATE_EXPORT_ON_SHAPES_FAST = {
    "batch_size": [4],
    "sequence_length": [19],
    "num_choices": [4],
}

NO_DYNAMIC_AXES_EXPORT_SHAPES_TRANSFORMERS = {
    "batch_size": [1, 3, 5],
    "num_choices": [2, 4],
    "sequence_length": [8, 33, 96],
}

PYTORCH_EXPORT_MODELS_TINY = {
    "albert": "hf-internal-testing/tiny-random-AlbertModel",
    "audio-spectrogram-transformer": "hf-internal-testing/tiny-random-ASTModel",
    "beit": "hf-internal-testing/tiny-random-BeitForImageClassification",
    "bert": {
        "hf-internal-testing/tiny-random-BertModel": [
            "feature-extraction",
            "fill-mask",
            "text-classification",
            "multiple-choice",
            "token-classification",
            "question-answering",
        ],
        "nreimers/BERT-Tiny_L-2_H-128_A-2": ["feature-extraction"],
    },
    "bart": "hf-internal-testing/tiny-random-bart",
    "big_bird": "hf-internal-testing/tiny-random-BigBirdModel",
    "bigbird_pegasus": "hf-internal-testing/tiny-random-bigbird_pegasus",
    "blenderbot-small": "hf-internal-testing/tiny-random-BlenderbotModel",
    "blenderbot": "hf-internal-testing/tiny-random-BlenderbotModel",
    "bloom": "hf-internal-testing/tiny-random-BloomModel",
    "camembert": "hf-internal-testing/tiny-random-camembert",
    "chinese_clip": "hf-internal-testing/tiny-random-ChineseCLIPModel",
    "clip": "hf-internal-testing/tiny-random-CLIPModel",
    "clip_vision_model": "fxmarty/clip-vision-model-tiny",
    "colpali": "hf-internal-testing/tiny-random-ColPaliForRetrieval",
    "convbert": "hf-internal-testing/tiny-random-ConvBertModel",
    "convnext": "hf-internal-testing/tiny-random-convnext",
    "convnextv2": "hf-internal-testing/tiny-random-ConvNextV2Model",
    "codegen": "hf-internal-testing/tiny-random-CodeGenModel",
    "cvt": "hf-internal-testing/tiny-random-CvTModel",
    "d_fine": "ustc-community/dfine-nano-coco",
    "data2vec-text": "hf-internal-testing/tiny-random-Data2VecTextModel",
    "data2vec-vision": "hf-internal-testing/tiny-random-Data2VecVisionModel",
    "data2vec-audio": "hf-internal-testing/tiny-random-Data2VecAudioModel",
    "deberta": "hf-internal-testing/tiny-random-DebertaModel",
    "deberta-v2": "hf-internal-testing/tiny-random-DebertaV2Model",
    "decision_transformer": "edbeeching/decision-transformer-gym-hopper-medium",
    "deit": "hf-internal-testing/tiny-random-DeiTModel",
    "dinov2": "hf-internal-testing/tiny-random-Dinov2Model",
    "donut": "fxmarty/tiny-doc-qa-vision-encoder-decoder",
    "donut-swin": "hf-internal-testing/tiny-random-DonutSwinModel",
    "detr": "hf-internal-testing/tiny-random-DetrModel",
    "distilbert": "hf-internal-testing/tiny-random-DistilBertModel",
    "dpt": "hf-internal-testing/tiny-random-DPTModel",
    "efficientnet": "hf-internal-testing/tiny-random-EfficientNetForImageClassification",
    "electra": "hf-internal-testing/tiny-random-ElectraModel",
    "encoder-decoder": {
        "hf-internal-testing/tiny-random-EncoderDecoderModel-bert-bert": ["text2text-generation"],
        "mohitsha/tiny-random-testing-bert2gpt2": ["text2text-generation", "text2text-generation-with-past"],
    },
    "esm": "hf-internal-testing/tiny-random-EsmModel",
    "falcon": {
        "fxmarty/really-tiny-falcon-testing": [
            "feature-extraction",
            "feature-extraction-with-past",
            "question-answering",
            "text-generation",
            "text-generation-with-past",
            "token-classification",
        ],
        "fxmarty/tiny-testing-falcon-alibi": ["text-generation", "text-generation-with-past"],
    },
    "flaubert": "hf-internal-testing/tiny-random-flaubert",
    "gemma": "fxmarty/tiny-random-GemmaForCausalLM",
    "glpn": "hf-internal-testing/tiny-random-GLPNModel",
    "gpt2": "hf-internal-testing/tiny-random-gpt2",
    "gpt_bigcode": "hf-internal-testing/tiny-random-GPTBigCodeModel",
    "gpt_neo": "hf-internal-testing/tiny-random-GPTNeoModel",
    "gpt_neox": "hf-internal-testing/tiny-random-GPTNeoXForCausalLM",
    "gptj": "hf-internal-testing/tiny-random-GPTJModel",
    "granite": "hf-internal-testing/tiny-random-GraniteForCausalLM",
    "groupvit": "hf-internal-testing/tiny-random-groupvit",
    "hiera": "hf-internal-testing/tiny-random-HieraForImageClassification",
    "ibert": "hf-internal-testing/tiny-random-IBertModel",
    "imagegpt": "hf-internal-testing/tiny-random-ImageGPTModel",
    "internlm2": "optimum-internal-testing/tiny-random-internlm2",
    "levit": "hf-internal-testing/tiny-random-LevitModel",
    "layoutlm": "hf-internal-testing/tiny-random-LayoutLMModel",
    "layoutlmv3": "hf-internal-testing/tiny-random-LayoutLMv3Model",
    "lilt": "hf-internal-testing/tiny-random-LiltModel",
    "llama": "fxmarty/tiny-llama-fast-tokenizer",
    "longt5": "fxmarty/tiny-random-working-LongT5Model",
    "longformer": "hf-internal-testing/tiny-random-LongformerModel",
    "m2m_100": "hf-internal-testing/tiny-random-m2m_100",
    "marian": "sshleifer/tiny-marian-en-de",  # hf-internal-testing ones are broken
    "markuplm": "hf-internal-testing/tiny-random-MarkupLMModel",
    "maskformer": "hf-internal-testing/tiny-random-MaskFormerForInstanceSegmentation",
    "mbart": "hf-internal-testing/tiny-random-mbart",
    "mctct": "hf-internal-testing/tiny-random-MCTCTModel",
    "megatron-bert": "hf-internal-testing/tiny-random-MegatronBertModel",
    "mgp-str": "hf-internal-testing/tiny-random-MgpstrForSceneTextRecognition",
    "mistral": "echarlaix/tiny-random-mistral",
    "mobilebert": "hf-internal-testing/tiny-random-MobileBertModel",
    "mobilenet_v2": "hf-internal-testing/tiny-random-MobileNetV2Model",
    "mobilenet_v1": "hf-internal-testing/tiny-random-MobileNetV1Model",
    "mobilevit": "hf-internal-testing/tiny-random-mobilevit",
    "modernbert": "hf-internal-testing/tiny-random-ModernBertForMaskedLM",
    "moonshine": "hf-internal-testing/tiny-random-MoonshineForConditionalGeneration",
    "mpnet": "hf-internal-testing/tiny-random-MPNetModel",
    "mpt": "hf-internal-testing/tiny-random-MptForCausalLM",
    "mt5": "lewtun/tiny-random-mt5",
    "musicgen": "hf-internal-testing/tiny-random-MusicgenForConditionalGeneration",
    "nystromformer": "hf-internal-testing/tiny-random-NystromformerModel",
    "olmo": "hf-internal-testing/tiny-random-OlmoForCausalLM",
    "olmo2": "hf-internal-testing/tiny-random-Olmo2ForCausalLM",
    "opt": "hf-internal-testing/tiny-random-OPTModel",
    "owlv2": "hf-internal-testing/tiny-random-Owlv2Model",
    "owlvit": "hf-tiny-model-private/tiny-random-OwlViTModel",
    "patchtst": "ibm/test-patchtst",
    "patchtsmixer": "ibm/test-patchtsmixer",
    "pegasus": "hf-internal-testing/tiny-random-PegasusModel",
    "perceiver": {
        "hf-internal-testing/tiny-random-language_perceiver": ["fill-mask", "text-classification"],
        "hf-internal-testing/tiny-random-vision_perceiver_conv": ["image-classification"],
    },
    "phi": "echarlaix/tiny-random-PhiForCausalLM",
    "phi3": "Xenova/tiny-random-Phi3ForCausalLM",
    "pix2struct": "fxmarty/pix2struct-tiny-random",
    "rembert": "hf-internal-testing/tiny-random-RemBertModel",
    "poolformer": "hf-internal-testing/tiny-random-PoolFormerModel",
    "pvt": "hf-internal-testing/tiny-random-PvtForImageClassification",
    "qwen2": "fxmarty/tiny-dummy-qwen2",
    "qwen3": "optimum-internal-testing/tiny-random-qwen3",
    "qwen3_moe": "optimum-internal-testing/tiny-random-qwen3_moe",
    "regnet": "hf-internal-testing/tiny-random-RegNetModel",
    "resnet": "hf-internal-testing/tiny-random-resnet",
    "roberta": "hf-internal-testing/tiny-random-RobertaModel",
    "roformer": "hf-internal-testing/tiny-random-RoFormerModel",
    "rt_detr": "PekingU/rtdetr_r18vd",
    "rt_detr_v2": "PekingU/rtdetr_v2_r18vd",
    "sam": "fxmarty/sam-vit-tiny-random",
    "segformer": "hf-internal-testing/tiny-random-SegformerModel",
    "siglip": "hf-internal-testing/tiny-random-SiglipModel",
    "siglip_vision_model": "hf-internal-testing/tiny-random-SiglipVisionModel",
    "smollm3": "onnx-internal-testing/tiny-random-SmolLM3ForCausalLM",
    "splinter": "hf-internal-testing/tiny-random-SplinterModel",
    "squeezebert": "hf-internal-testing/tiny-random-SqueezeBertModel",
    "swin": "hf-internal-testing/tiny-random-SwinModel",
    "swinv2": "hf-internal-testing/tiny-random-Swinv2Model",
    "swin2sr": "hf-internal-testing/tiny-random-Swin2SRModel",
    "t5": "hf-internal-testing/tiny-random-t5",
    "table-transformer": "hf-internal-testing/tiny-random-TableTransformerModel",
    "vit": "hf-internal-testing/tiny-random-vit",
    "vit_mae": "hf-internal-testing/tiny-random-ViTMAEModel",
    "vit_msn": "hf-internal-testing/tiny-random-ViTMSNForImageClassification",
    "vits": "echarlaix/tiny-random-vits",
    "vitpose": "hf-internal-testing/tiny-random-VitPoseForPoseEstimation",
    "yolos": "hf-internal-testing/tiny-random-YolosModel",
    "whisper": "optimum-internal-testing/tiny-random-whisper",
    "hubert": "hf-internal-testing/tiny-random-HubertModel",
    "wav2vec2": "hf-internal-testing/tiny-random-Wav2Vec2Model",
    "wav2vec2-conformer": "hf-internal-testing/tiny-random-wav2vec2-conformer",
    "wavlm": {
        "hf-internal-testing/tiny-random-wavlm": [
            "feature-extraction",
            "automatic-speech-recognition",
            "audio-classification",
        ],
        "hf-internal-testing/tiny-random-WavLMForCTC": ["audio-frame-classification"],
        "hf-internal-testing/tiny-random-WavLMForXVector": ["audio-xvector"],
    },
    "sew": "hf-internal-testing/tiny-random-SEWModel",
    "sew-d": "hf-internal-testing/tiny-random-SEWDModel",
    "unispeech": "hf-internal-testing/tiny-random-unispeech",
    "unispeech-sat": {
        "hf-internal-testing/tiny-random-unispeech-sat": [
            "feature-extraction",
            "automatic-speech-recognition",
            "audio-classification",
        ],
        "hf-internal-testing/tiny-random-UniSpeechSatForPreTraining": ["audio-frame-classification"],
        "hf-internal-testing/tiny-random-UniSpeechSatForXVector": ["audio-xvector"],
    },
    "speech_to_text": "hf-internal-testing/tiny-random-Speech2TextModel",
    "speecht5": "hf-internal-testing/tiny-random-SpeechT5ForTextToSpeech",
    "xlm": "hf-internal-testing/tiny-random-XLMModel",
    "xlm-roberta": "hf-internal-testing/tiny-xlm-roberta",
    "vision-encoder-decoder": {
        "hf-internal-testing/tiny-random-VisionEncoderDecoderModel-vit-gpt2": [
            "image-to-text",
            "image-to-text-with-past",
        ],
        "microsoft/trocr-small-handwritten": ["image-to-text", "image-to-text-with-past"],
        "fxmarty/tiny-doc-qa-vision-encoder-decoder": [
            "document-question-answering",
            "document-question-answering-with-past",
        ],
    },
}

# TODO: enable export slow tests
PYTORCH_EXPORT_MODELS_LARGE = {
    "albert": "albert-base-v2",
    "audio-spectrogram-transformer": "nielsr/audio-spectogram-transformer-finetuned-audioset-10-10-0.4593",
    "beit": "microsoft/beit-base-patch16-224",
    "bert": "bert-base-cased",
    "bart": "facebook/bart-base",
    "big_bird": "google/bigbird-roberta-base",
    "bigbird_pegasus": "hf-internal-testing/tiny-random-bigbird_pegasus",
    "blenderbot-small": "facebook/blenderbot_small-90M",
    "blenderbot": "facebook/blenderbot-90M",
    "bloom": "bigscience/bloom-560m",
    "camembert": "camembert-base",
    "clip": "openai/clip-vit-base-patch32",
    "convbert": "YituTech/conv-bert-base",
    "convnext": "facebook/convnext-tiny-224",
    "codegen": "Salesforce/codegen-350M-multi",
    "d_fine": "ustc-community/dfine-nano-coco",
    "data2vec-text": "facebook/data2vec-text-base",
    "data2vec-vision": "facebook/data2vec-vision-base",
    "data2vec-audio": "facebook/data2vec-audio-base",
    "deberta": "microsoft/deberta-base",
    "deberta-v2": "microsoft/deberta-v2-xlarge",
    "deit": "facebook/deit-small-patch16-224",
    "detr": "facebook/detr-resnet-50",
    "distilbert": "distilbert-base-cased",
    "electra": "google/electra-base-generator",
    "encoder-decoder": "patrickvonplaten/bert2bert_cnn_daily_mail",
    "flaubert": "flaubert/flaubert_small_cased",
    "gemma": "google/gemma-2b",
    "gpt2": "gpt2",
    "gpt_neo": "EleutherAI/gpt-neo-125M",
    "gpt_neox": "EleutherAI/gpt-neox-20b",
    "gptj": "architext/gptj-162M",
    "groupvit": "nvidia/groupvit-gcc-yfcc",
    "hiera": "facebook/hiera-tiny-224-in1k-hf",
    "ibert": "kssteven/ibert-roberta-base",
    "imagegpt": "openai/imagegpt-small",
    "levit": "facebook/levit-128S",
    "layoutlm": "microsoft/layoutlm-base-uncased",
    "layoutlmv3": "microsoft/layoutlmv3-base",
    "lilt": "SCUT-DLVCLab/lilt-roberta-en-base",
    "llama": "decapoda-research/llama-65b-hf",
    "longt5": "google/long-t5-local-base",
    "longformer": "allenai/longformer-base-4096",
    "m2m_100": "facebook/m2m100_418M",
    "marian": "Helsinki-NLP/opus-mt-en-de",
    "markuplm": "hf-internal-testing/tiny-random-MarkupLMModel",
    "maskformer": "facebook/maskformer-swin-tiny-coco",
    "mbart": "sshleifer/tiny-mbart",
    "mgp-str": "alibaba-damo/mgp-str-base",
    "mobilebert": "google/mobilebert-uncased",
    "mobilenet_v1": "google/mobilenet_v1_0.75_192",
    "mobilenet_v2": "google/mobilenet_v2_0.35_96",
    "mobilevit": "apple/mobilevit-small",
    "modernbert": "answerdotai/ModernBERT-base",
    "moonshine": "UsefulSensors/moonshine-tiny",
    "mpt": "mosaicml/mpt-7b",
    "mt5": "google/mt5-small",
    "musicgen": "facebook/musicgen-small",
    "nystromformer": "hf-internal-testing/tiny-random-NystromformerModel",
    "owlv2": "google/owlv2-base-patch16",
    "owlvit": "google/owlvit-base-patch32",
    "perceiver": "deepmind/language-perceiver",
    "rembert": "google/rembert",
    "poolformer": "hf-internal-testing/tiny-random-PoolFormerModel",
    "pvt": "hf-internal-testing/tiny-random-PvtForImageClassification",
    "regnet": "facebook/regnet-y-040",
    "resnet": "microsoft/resnet-50",
    "roberta": "roberta-base",
    "roformer": "junnyu/roformer_chinese_base",
    "rt_detr": "PekingU/rtdetr_r101vd",
    "rt_detr_v2": "PekingU/rtdetr_v2_r101vd",
    "sam": "facebook/sam-vit-base",
    "segformer": "nvidia/segformer-b0-finetuned-ade-512-512",
    "siglip": "google/siglip-base-patch16-224",
    "splinter": "hf-internal-testing/tiny-random-SplinterModel",
    "squeezebert": "squeezebert/squeezebert-uncased",
    "swin": "microsoft/swin-tiny-patch4-window7-224",
    "swinv2": "microsoft/swinv2-tiny-patch4-window16-256",
    "t5": "t5-small",
    "table-transformer": "microsoft/table-transformer-detection",
    "vit": "google/vit-base-patch16-224",
    "vit_mae": "facebook/vit-mae-base",
    "vit_msn": "facebook/vit-msn-small",
    "vitpose": "usyd-community/vitpose-plus-small",
    "yolos": "hustvl/yolos-tiny",
    "whisper": "openai/whisper-tiny.en",
    "hubert": "facebook/hubert-base-ls960",
    "wav2vec2": "facebook/wav2vec2-base-960h",
    "wav2vec2-conformer": "facebook/wav2vec2-conformer-rel-pos-large-960h-ft",
    "wavlm": "microsoft/wavlm-base-plus-sv",
    "sew": "asapp/sew-tiny-100k",
    "sew-d": "asapp/sew-d-tiny-100k-ft-ls100h",
    "unispeech": "microsoft/unispeech-1350-en-353-fr-ft-1h",
    "unispeech-sat": "microsoft/unispeech-sat-base",
    "mctct": "speechbrain/m-ctc-t-large",
    "speech_to_text": "codenamewei/speech_to_text",
    "xlm": "xlm-clm-ende-1024",
    "xlm-roberta": "Unbabel/xlm-roberta-comet-small",
}

TENSORFLOW_EXPORT_MODELS = {
    "albert": "hf-internal-testing/tiny-albert",
    "bert": "bert-base-cased",
    "camembert": "camembert-base",
    "distilbert": "distilbert-base-cased",
    "roberta": "roberta-base",
}

PYTORCH_DIFFUSION_MODEL = {
    "flux": "optimum-internal-testing/tiny-random-flux",
    "latent-consistency": "echarlaix/tiny-random-latent-consistency",
    "stable-diffusion": "hf-internal-testing/tiny-stable-diffusion-torch",
    "stable-diffusion-3": "yujiepan/stable-diffusion-3-tiny-random",
    "stable-diffusion-xl": "echarlaix/tiny-random-stable-diffusion-xl",
}

PYTORCH_TIMM_MODEL = {
    "default-timm-config": {
        "timm/inception_v3.tf_adv_in1k": ["image-classification"],  # one model is enought to test timm integration
    }
}

PYTORCH_SENTENCE_TRANSFORMERS_MODEL = {
    "clip": "sentence-transformers/clip-ViT-B-32",
    "transformer": {
        "sentence-transformers/all-MiniLM-L6-v2": ["feature-extraction", "sentence-similarity"],
        "fxmarty/tiny-dummy-mistral-sentence-transformer": ["feature-extraction", "sentence-similarity"],
    },
}


PYTORCH_TRANSFORMERS_MODEL_NO_DYNAMIC_AXES = {
    "albert": "hf-internal-testing/tiny-random-AlbertModel",
    "gpt2": "hf-internal-testing/tiny-random-gpt2",
    "roberta": "hf-internal-testing/tiny-random-RobertaModel",
    "roformer": "hf-internal-testing/tiny-random-RoFormerModel",
}


PYTORCH_TIMM_MODEL_NO_DYNAMIC_AXES = {
    "default-timm-config": {
        "timm/ese_vovnet39b.ra_in1k": ["image-classification"],
        "timm/ese_vovnet19b_dw.ra_in1k": ["image-classification"],
    }
}

PYTORCH_EXPORT_MODELS_TINY_SLIM = {
    k: v for k, v in PYTORCH_EXPORT_MODELS_TINY.items() if k in ["modernbert", "llama", "t5", "whisper"]
}
